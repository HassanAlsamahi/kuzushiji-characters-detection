{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "from PIL import ImageOps,ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage.transform import resize\n",
    "from IPython.display import FileLink\n",
    "\n",
    "gpu_available = torch.cuda.is_available()\n",
    "print(gpu_available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 15\n",
    "\n",
    "#Uncomment to download the font.\n",
    "# From https://www.google.com/get/noto/\n",
    "#!wget -q --show-progress https://noto-website-2.storage.googleapis.com/pkgs/NotoSansCJKjp-hinted.zip\n",
    "#!unzip -p NotoSansCJKjp-hinted.zip NotoSansCJKjp-Regular.otf > NotoSansCJKjp-Regular.otf\n",
    "#!rm NotoSansCJKjp-hinted.zip\n",
    "\n",
    "font = ImageFont.truetype('./kuzishiju-recognition/NotoSansCJKjp-Regular.otf', fontsize, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "with open('train.csv') as csvfile:\n",
    "    data =csv.reader(csvfile,delimiter=',')\n",
    "    for row in data:\n",
    "        splitter = row[1].split()\n",
    "        for word in splitter:\n",
    "            if word.startswith('U'):\n",
    "                if not word in classes:\n",
    "                    classes.append(word)\n",
    "\n",
    "classes = sorted(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('unicode_translation.csv')\n",
    "df = pd.DataFrame(data)\n",
    "unicode_map = {codepoint: char for codepoint, char in data.values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMaxWidthMaxHeight(images_list,path):\n",
    "    max_height, max_width = 0,0\n",
    "    for image in images_list:\n",
    "        image_path = os.path.join(path,image)\n",
    "        img = Image.open(image_path)\n",
    "        if img.size[0] > max_width:\n",
    "            max_width = img.size[0]\n",
    "            \n",
    "        if img.size[1] > max_height:\n",
    "            max_height = img.size[1]\n",
    "            \n",
    "    return max_width,max_height\n",
    "    \n",
    "\n",
    "def downSample(img,scale_size,max_height=4493,max_width=3248):\n",
    "    \n",
    "    new_w = (max_width - img.size[0])\n",
    "    new_h = (max_height - img.size[1])\n",
    "    if new_w%2 != 0:\n",
    "        right_pad = int(new_w/2)\n",
    "        left_pad = int(new_w/2) + 1\n",
    "        if new_h%2 !=0:\n",
    "            top_pad = int(new_h/2)\n",
    "            bottom_pad = int(new_h/2) + 1       \n",
    "        else:\n",
    "            top_pad = int(new_h/2)\n",
    "            bottom_pad = int(new_h/2)\n",
    "    else:\n",
    "        right_pad = int(new_w/2)\n",
    "        left_pad = int(new_w/2)\n",
    "        if new_h%2 !=0:\n",
    "            top_pad = int(new_h/2)\n",
    "            bottom_pad = int(new_h/2) + 1       \n",
    "        else:\n",
    "            top_pad = int(new_h/2)\n",
    "            bottom_pad = int(new_h/2)\n",
    "    padding = (right_pad,top_pad,left_pad,bottom_pad)\n",
    "    new_img = ImageOps.expand(img,padding)\n",
    "    new_img = new_img.resize((int(new_img.size[0]*scale_size),int(new_img.size[1]*scale_size)))\n",
    "    return new_img,right_pad,left_pad,top_pad,bottom_pad\n",
    "\n",
    "\n",
    "\n",
    "def newCoords(x,y,w,h,right_pad,left_pad,top_pad,bottom_pad,scale_size):\n",
    "    x,y,w,h = int((x+left_pad)*scale_size),int((y+bottom_pad)*scale_size),int(w*scale_size),int(h*scale_size)\n",
    "    x1 = x + w\n",
    "    y1 = y + h\n",
    "    \n",
    "    return x,y,x1,y1\n",
    "\n",
    "def return_original(img,right_pad,left_pad,top_pad,bottom_pad,scale_size):\n",
    "    \n",
    "    img = img[int(top_pad*scale_size):img.shape[0]-int(bottom_pad*scale_size)-1,\n",
    "              int(right_pad*scale_size):img.shape[1]-int(left_pad*scale_size)-1]\n",
    "    expand_scale = 1/scale_size\n",
    "    img = resize(img,(img.shape[0]*expand_scale,img.shape[1]*expand_scale,img.shape[2]))\n",
    "   \n",
    "    return img\n",
    "\n",
    "def old_coords(bbox,right_pad,left_pad,top_pad,bottom_pad,scale_size):\n",
    "    x,y,x1,y1 = bbox\n",
    "    expand_scale = 1/scale_size\n",
    "    x,y,x1,y1 = int((x*expand_scale)-left_pad),int((y*expand_scale)-bottom_pad),int((x1*expand_scale)-right_pad),int((y1*expand_scale)-bottom_pad)\n",
    "    \n",
    "    return x,y,x1,y1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharsDataset(Dataset):\n",
    "    def __init__(self,path,csvfile=None,train=True):\n",
    "        self.images = os.listdir(path)\n",
    "        self.path = path\n",
    "        self.train = train\n",
    "        self.csvfile = csvfile\n",
    "        #self.max_width, self.max_height = calcMaxWidthMaxHeight(self.images,path) #uncomment to calculate the max width and height in your dataset\n",
    "        if train:\n",
    "            data_temp = pd.read_csv(csvfile,index_col=0)\n",
    "            df_temp = pd.DataFrame(data_temp)\n",
    "            self.df_temp = df_temp.dropna()\n",
    "            for image in self.images:\n",
    "                if (image[:-4] in self.df_temp.index) == False:\n",
    "                    self.images = list(filter((image).__ne__,self.images))\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        scale_size = 0.2\n",
    "        image = self.images[idx]\n",
    "        image_path = os.path.join(self.path,image)\n",
    "        img = Image.open(image_path)\n",
    "        new_img,right_pad,left_pad,top_pad,bottom_pad = downSample(img,scale_size) #insert the max_width, max_height if custom dataset.        \n",
    "        img_tensor = torchvision.transforms.functional.to_tensor(new_img)\n",
    "        if self.train is True:\n",
    "            df = self.df_temp\n",
    "            _id = image[:-4]\n",
    "            ret = df.loc[_id,:]\n",
    "            labels = ret[0].split()        \n",
    "            goals = {}\n",
    "            targets = []\n",
    "            bboxes = []\n",
    "            for i in range(0,len(labels),5):   \n",
    "                final_label = labels[i:i+5]\n",
    "                label,x,y,w,h = final_label[0],int(final_label[1]),int(final_label[2]),int(final_label[3]),int(final_label[4])\n",
    "                index = classes.index(label)\n",
    "                x,y,x1,y1 = newCoords(x,y,w,h,right_pad,left_pad,top_pad,bottom_pad,scale_size)\n",
    "                targets.append(index)\n",
    "                bboxes.append([x,y,x1,y1])\n",
    "            targets = torch.tensor(targets,dtype=torch.int64)\n",
    "            bboxes = torch.as_tensor(bboxes,dtype=torch.float32)\n",
    "            goals['labels'] = targets\n",
    "            goals['boxes']= bboxes\n",
    "            \n",
    "            return img_tensor,goals\n",
    "        else:\n",
    "             return img_tensor,right_pad,left_pad,top_pad,bottom_pad,image\n",
    "         \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "train_data = CharsDataset('train_images','train.csv')\n",
    "print('elapse time = ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    size = len(batch)\n",
    "    tensors_images = []\n",
    "    tensors_targets = []\n",
    "    for i in range(0,size):\n",
    "        data = batch[i][0]\n",
    "        \n",
    "        labels = batch[i][1]['labels']\n",
    "        bboxes = batch[i][1]['boxes']\n",
    "        \n",
    "        tensors_images.append(data)\n",
    "        tensors_targets.append({'labels':torch.tensor(labels,dtype=torch.int64),'boxes':torch.tensor(bboxes,dtype=torch.float32)})\n",
    "    imgs = torch.stack([i for i in tensors_images],dim=0)\n",
    "    \n",
    "    return imgs,tensors_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(data,model=None,train=True):\n",
    "    number = np.random.randint(0,len(data))\n",
    "    if train:\n",
    "        data,targets = data[number]\n",
    "        img = np.transpose(data.numpy(),(1,2,0))\n",
    "        labels = targets['labels']\n",
    "        boxes = targets['boxes']\n",
    "    else:\n",
    "        data,right_pad,left_pad,top_pad,bottom_pad,name = data[number]\n",
    "        data = data.unsqueeze(dim=0)\n",
    "        if gpu_available:\n",
    "            data = data.cuda()\n",
    "            model = model.cuda()\n",
    "        model.eval()\n",
    "        output = model(data)\n",
    "        labels = output[0]['labels']\n",
    "        boxes = output[0]['boxes']\n",
    "        #data = data.cuda()\n",
    "        if gpu_available:\n",
    "           data = data.cpu()\n",
    "        data = data.squeeze()\n",
    "        img = np.transpose(data.numpy(),(1,2,0))\n",
    "        img = return_original(img,right_pad,left_pad,top_pad,bottom_pad,scale_size=0.2)\n",
    "    \n",
    "    \n",
    "    box_img = np.zeros_like(img)\n",
    "    box_img = Image.fromarray(box_img,mode='RGB')\n",
    "    box_img = ImageOps.grayscale(box_img)\n",
    "    \n",
    "    char_img = np.zeros_like(img)\n",
    "    char_img = Image.fromarray(char_img,mode='RGB')\n",
    "    char_img = ImageOps.grayscale(char_img)\n",
    "    \n",
    "    box_draw = ImageDraw.Draw(box_img)\n",
    "    char_draw = ImageDraw.Draw(char_img)\n",
    "    for label,box in zip(labels,boxes):\n",
    "        if not train:\n",
    "            x,y,x2,y2 = old_coords(box,right_pad,left_pad,top_pad,bottom_pad,0.2)\n",
    "            font = ImageFont.truetype('../kuzishiju-training-2/NotoSansCJKjp-Regular.otf', 70, encoding='utf-8')\n",
    "            width = 5\n",
    "        else:\n",
    "            [x,y,x2,y2] = box\n",
    "            width = 1\n",
    "            font = ImageFont.truetype('../kuzishiju-training-2/NotoSansCJKjp-Regular.otf', fontsize, encoding='utf-8')\n",
    "        w,h = x2-x , y2-y\n",
    "        char = unicode_map[classes[label]]\n",
    "        box_draw.rectangle([x,y,x2,y2],outline=(255),width=width)\n",
    "        char_draw.text((x + w + fontsize/4, y + h/2 - fontsize), char, fill=(255), font=font)\n",
    "     \n",
    "    box_img = np.array(box_img)\n",
    "    char_img = np.array(char_img)\n",
    "    img[box_img > 0] = (255,0,0)\n",
    "    img[char_img > 0] = (0,0,255)\n",
    "    \n",
    "    plt.figure(figsize=(50,20))\n",
    "    plt.imshow(img)\n",
    "    \n",
    "random_sampling(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_workers = 0 \n",
    "valid_size = 0.2\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False,num_classes=4212)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_dataloader,epochs=20,lr=1e-3):\n",
    "    print('Training the network')\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr = lr)\n",
    "    \n",
    "    if gpu_available:\n",
    "        model = model.cuda()\n",
    "        \n",
    "    for epoch in range(1,epochs+1):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "        model.train()\n",
    "        for data,target in tqdm(train_dataloader):\n",
    "            if gpu_available:\n",
    "                data = data.cuda()\n",
    "                target = [{k: v.cuda() for k, v in t.items()} for t in target]\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data,target)\n",
    "            loss = sum(loss for loss in output.values())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()*data.size(0)\n",
    "     \n",
    "        train_loss = train_loss/len(train_dataloader.dataset)    \n",
    "        print(\"Epoch {}/{} ...... Train Loss {:.6f}\".format(epoch,epochs,train_loss))\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "start = time.time()\n",
    "train(model,train_loader)\n",
    "print('Training time:',time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"kuzushiji-recognition.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('kuzushiji-recognition.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = CharsDataset('test_images',train=False)\n",
    "random_sampling(test_data,model,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To create sample file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_file(loader,model):\n",
    "    with torch.no_grad():\n",
    "        images = []\n",
    "        goals = []\n",
    "        for data,right_pad,left_pad,top_pad,bottom_pad,name in tqdm(loader):\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad=False\n",
    "            model.eval()\n",
    "            if gpu_available:\n",
    "                model = model.cuda()\n",
    "                data = data.cuda()\n",
    "            data = data.unsqueeze(dim=0)\n",
    "            output = model(data)\n",
    "            labels = output[0]['labels']\n",
    "            boxes = output[0]['boxes']\n",
    "            \n",
    "            if gpu_available:\n",
    "               data = data.cpu()\n",
    "            data = data.squeeze()\n",
    "            img = np.transpose(data.numpy(),(1,2,0))\n",
    "            img = return_original(img,right_pad,left_pad,top_pad,bottom_pad,scale_size=0.2)\n",
    "\n",
    "            targets = []\n",
    "            for label,box in zip(labels,boxes):\n",
    "                x,y,x2,y2 = old_coords(box,right_pad,left_pad,top_pad,bottom_pad,0.2)\n",
    "                w,h = x2-x,y2-y\n",
    "                x_center,y_center = int((x+x2)/2),int((y+y2)/2)\n",
    "                char = classes[label]\n",
    "                targets.append(' '.join(map(str,[char,x_center,y_center])))\n",
    "            goals.append(' '.join(map(str,targets)))\n",
    "            images.append(name[:-4])\n",
    "        dicts = {'image_id':images,'labels':goals}\n",
    "        df_dict = pd.DataFrame.from_dict(dicts)   \n",
    "        return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "start = time.time()\n",
    "df_dict = create_sample_file(test_data,model)\n",
    "print(time.time()-start)\n",
    "df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict.to_csv('../../working/submission6.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
